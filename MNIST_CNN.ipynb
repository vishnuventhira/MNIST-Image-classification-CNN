{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#For Modelling\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#Additional\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "\n",
    "##Neural Network \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#CNN \n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "#Image Pre-Processing\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataset is available in keras datasets\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "#Loading the data into test and train objects\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the train labels\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape dataset to have a single channel\n",
    "train_images_cnn = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "test_images_cnn = test_images.reshape((test_images.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting labels to categorical features\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a holdout for validation and using the rest for train. (80/20)\n",
    "\n",
    "This will help us tune the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_partial_cnn, x_val_cnn, y_train_partial_cnn, y_val_cnn = train_test_split(train_images_cnn, train_labels, test_size = 0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Seeing the shape of test and tarin\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "\n",
    "#the shape looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at one individual point\n",
    "#In this each list corresponds to a row of pixels\n",
    "\n",
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now lets look at how these matrices values are displayed as images\n",
    "\n",
    "plt.imshow(train_images[100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first basic model \n",
    "\n",
    "<b> This has not been mentioned in the assignment but we just wanted to give it a shot and see how the code for digits recognition performs on the fashion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the network architecture\n",
    "\n",
    "network = models.Sequential() #sequential models\n",
    "network.add(layers.Flatten())\n",
    "network.add(layers.Dense(512, activation='relu')) # 512 features are created from the input ones\n",
    "network.add(layers.Dense(10, activation='softmax')) #This is the final layer that has ten categories who probabilties add to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 15s 314us/step - loss: 19.4788 - accuracy: 0.7148\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 12s 244us/step - loss: 0.8634 - accuracy: 0.7937s - loss: 0.8652 - accura\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 11s 224us/step - loss: 0.6781 - accuracy: 0.8204\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 13s 273us/step - loss: 0.6385 - accuracy: 0.8285\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 13s 265us/step - loss: 0.5707 - accuracy: 0.8394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f42c024d68>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(x_train_partial_cnn, y_train_partial_cnn, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 898us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss_cnn, test_acc_cnn = network.evaluate(test_images_cnn, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6830000281333923"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer perceptron\n",
    "\n",
    "* As mentioned in the assignment it needs to have four hidden layers.\n",
    "* Also, we have tried the funneling approach reducing the number of nodes in each progressive layer\n",
    "* A lot of code has been replicated from FChollets book to which we give due credit and appreciation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model1 architecture\n",
    "\n",
    "model1 = models.Sequential() #sequential models\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(512, activation='relu')) # 512 features are created from the input ones\n",
    "model1.add(layers.Dense(256, activation='relu')) # 256 features are created from the input ones\n",
    "model1.add(layers.Dense(128, activation='relu')) # 128 features are created from the input ones\n",
    "model1.add(layers.Dense(64, activation='relu')) # 64 features are created from the input ones\n",
    "model1.add(layers.Dense(10, activation='softmax')) #This is the final layer that has ten categories who probabilties add to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "# since many categories are present, I have used categorical_crossentropy\n",
    "\n",
    "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 13s 270us/step - loss: 14.7015 - accuracy: 0.5609 - val_loss: 1.3388 - val_accuracy: 0.6758\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 12s 259us/step - loss: 1.1452 - accuracy: 0.6973 - val_loss: 0.6281 - val_accuracy: 0.7708\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 13s 262us/step - loss: 0.7696 - accuracy: 0.7465 - val_loss: 0.5311 - val_accuracy: 0.8202\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 12s 243us/step - loss: 0.5756 - accuracy: 0.7957 - val_loss: 0.6299 - val_accuracy: 0.8118\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 12s 258us/step - loss: 0.5126 - accuracy: 0.8151 - val_loss: 0.4057 - val_accuracy: 0.8518\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 12s 254us/step - loss: 0.4570 - accuracy: 0.8318 - val_loss: 0.4780 - val_accuracy: 0.8292\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 12s 242us/step - loss: 0.4304 - accuracy: 0.8435 - val_loss: 0.4304 - val_accuracy: 0.8445\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 12s 253us/step - loss: 0.4055 - accuracy: 0.8506 - val_loss: 0.4150 - val_accuracy: 0.8488\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 13s 265us/step - loss: 0.3768 - accuracy: 0.8620 - val_loss: 0.4088 - val_accuracy: 0.8587\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 12s 246us/step - loss: 0.3663 - accuracy: 0.8668 - val_loss: 0.4510 - val_accuracy: 0.8475\n"
     ]
    }
   ],
   "source": [
    "# The history variable will have all the parameters for model fitting\n",
    "#This will be easier for visualization and tuning\n",
    "\n",
    "history = model1.fit(x_train_partial_cnn,\n",
    "                    y_train_partial_cnn,\n",
    "                    epochs=25,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val_cnn, y_val_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VPXZ//H3DUTCJiDEjVQCtY8KGCCmCgUFwVrccK2KUJdqUbtotX0qpbYuLVet8lNErb+ildqSQn20VuuGVlBq2wdNWAW0WI0YQQi0IKuacD9/nJMwCZNkSDJzQs7ndV1zzZkzZ873ngnMZ77fs5m7IyIi8dUm6gJERCRaCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYE0mZm1NbNtZnZEcy4bJTM70syafd9qMzvFzEoTHr9tZiemsmwj2nrYzCY39vX1rPdnZvab5l6vRKdd1AVI5pnZtoSHHYFPgMrw8dXuXrQv63P3SqBzcy8bB+5+VHOsx8yuAia4+8iEdV/VHOuW1k9BEEPuXv1FHP7ivMrd/1LX8mbWzt0rMlGbiGSehoZkL2HX/w9mNtvMtgITzGyomf2vmW02s3VmNt3MssLl25mZm1le+HhW+PzzZrbVzP5hZn32ddnw+dPM7J9mtsXM7jOzv5nZ5XXUnUqNV5vZO2b2HzObnvDatmZ2j5ltMrN/AWPq+XxuNrM5teY9YGZ3h9NXmdmq8P38K/y1Xte6ysxsZDjd0cx+F9a2AjguSbvvhutdYWZjw/nHAvcDJ4bDbhsTPttbE15/TfjeN5nZn8zssFQ+m4aY2TlhPZvNbJ6ZHZXw3GQzW2tmH5vZWwnvdYiZLQrnrzezu1JtT9LA3XWL8Q0oBU6pNe9nwKfAWQQ/FjoAXwROIOhF9gX+CXw7XL4d4EBe+HgWsBEoBLKAPwCzGrHswcBW4OzwuRuBz4DL63gvqdT4FNAVyAP+XfXegW8DK4BcoAewIPjvkbSdvsA2oFPCujcAheHjs8JlDBgF7ATyw+dOAUoT1lUGjAynpwKvAN2B3sDKWsteCBwW/k0uCWs4JHzuKuCVWnXOAm4Np08NaxwEZAO/BOal8tkkef8/A34TTh8T1jEq/BtNDj/3LKA/8D5waLhsH6BvOP0GMC6c7gKcEPX/hTjf1COQurzm7n92993uvtPd33D3he5e4e7vAjOAEfW8/nF3L3b3z4Aigi+gfV32TGCJuz8VPncPQWgklWKNP3f3Le5eSvClW9XWhcA97l7m7puAO+pp513gTYKAAvgysNndi8Pn/+zu73pgHvAykHSDcC0XAj9z9/+4+/sEv/IT233M3deFf5PfE4R4YQrrBRgPPOzuS9x9FzAJGGFmuQnL1PXZ1Odi4Gl3nxf+je4ADiQI5AqC0OkfDi++F352EAT6F8ysh7tvdfeFKb4PSQMFgdTlg8QHZna0mT1rZh+Z2cfA7UDPel7/UcL0DurfQFzXsocn1uHuTvALOqkUa0ypLYJfsvX5PTAunL6EIMCq6jjTzBaa2b/NbDPBr/H6Pqsqh9VXg5ldbmZLwyGYzcDRKa4XgvdXvT53/xj4D9ArYZl9+ZvVtd7dBH+jXu7+NvA9gr/DhnCo8dBw0SuAfsDbZva6mZ2e4vuQNFAQSF1q7zr5K4JfwUe6+4HATwiGPtJpHcFQDQBmZtT84qqtKTWuAz6X8Lih3Vv/AJwS/qI+myAYMLMOwOPAzwmGbboBL6ZYx0d11WBmfYEHgWuBHuF630pYb0O7uq4lGG6qWl8XgiGoD1Ooa1/W24bgb/YhgLvPcvdhBMNCbQk+F9z9bXe/mGD47/8BT5hZdhNrkUZSEEiqugBbgO1mdgxwdQbafAYoMLOzzKwdcD2Qk6YaHwO+a2a9zKwHcFN9C7v7euA1YCbwtruvDp9qDxwAlAOVZnYmMHofaphsZt0sOM7i2wnPdSb4si8nyMSrCHoEVdYDuVUbx5OYDVxpZvlm1p7gC/mv7l5nD2sfah5rZiPDtv+bYLvOQjM7xsxODtvbGd4qCd7A18ysZ9iD2BK+t91NrEUaSUEgqfoecBnBf/JfEfwiTqvwy/Yi4G5gE/B5YDHBcQ/NXeODBGP5ywk2ZD6ewmt+T7Dx9/cJNW8GbgCeJNjgegFBoKXiFoKeSSnwPPDbhPUuA6YDr4fLHA0kjqu/BKwG1ptZ4hBP1etfIBiieTJ8/REE2w2axN1XEHzmDxKE1BhgbLi9oD1wJ8F2nY8IeiA3hy89HVhlwV5pU4GL3P3TptYjjWPBsKtIy2dmbQmGIi5w979GXY9Ia6EegbRoZjbGzLqGwws/JtgT5fWIyxJpVRQE0tINB94lGF4YA5zj7nUNDYlII2hoSEQk5tQjEBGJuf3ipHM9e/b0vLy8qMsQEdmvlJSUbHT3+na5BvaTIMjLy6O4uDjqMkRE9itm1tAR8oCGhkREYk9BICIScwoCEZGY2y+2EYhIZn322WeUlZWxa9euqEuRFGRnZ5Obm0tWVl2nmqqfgkBE9lJWVkaXLl3Iy8sjOOmrtFTuzqZNmygrK6NPnz4NvyCJVjs0VFQEeXnQpk1wX7RPl2MXibddu3bRo0cPhcB+wMzo0aNHk3pvrbJHUFQEEyfCjh3B4/ffDx4DjG/y+RZF4kEhsP9o6t+qVfYIfvSjPSFQZceOYL6IiNTUKoNgzZp9my8iLcumTZsYNGgQgwYN4tBDD6VXr17Vjz/9NLXLFlxxxRW8/fbb9S7zwAMPUNRM48bDhw9nyZIlzbKuTGuVQ0NHHBEMByWbLyLNr6go6HGvWRP8P5sypWnDsD169Kj+Ur311lvp3Lkz3//+92ss4+64O23aJP89O3PmzAbb+da3vtX4IluRVtkjmDIFOnasOa9jx2C+iDSvqm1y778P7nu2yaVjB4133nmHAQMGcM0111BQUMC6deuYOHEihYWF9O/fn9tvv7162apf6BUVFXTr1o1JkyYxcOBAhg4dyoYNGwC4+eabmTZtWvXykyZN4vjjj+eoo47i73//OwDbt2/n/PPPZ+DAgYwbN47CwsIGf/nPmjWLY489lgEDBjB58mQAKioq+NrXvlY9f/r06QDcc8899OvXj4EDBzJhwoRm/8xS0SqDYPx4mDEDevcGs+B+xgxtKBZJh0xvk1u5ciVXXnklixcvplevXtxxxx0UFxezdOlSXnrpJVauXLnXa7Zs2cKIESNYunQpQ4cO5ZFHHkm6bnfn9ddf56677qoOlfvuu49DDz2UpUuXMmnSJBYvXlxvfWVlZdx8883Mnz+fxYsX87e//Y1nnnmGkpISNm7cyPLly3nzzTe59NJLAbjzzjtZsmQJS5cu5f7772/ip9M4rTIIIPjSLy2F3buDe4WASHpkepvc5z//eb74xS9WP549ezYFBQUUFBSwatWqpEHQoUMHTjvtNACOO+44SktLk677vPPO22uZ1157jYsvvhiAgQMH0r9//3rrW7hwIaNGjaJnz55kZWVxySWXsGDBAo488kjefvttrr/+eubOnUvXrl0B6N+/PxMmTKCoqKjRB4Q1VasNAhHJjLq2vaVrm1ynTp2qp1evXs29997LvHnzWLZsGWPGjEm6P/0BBxxQPd22bVsqKiqSrrt9+/Z7LbOvF++qa/kePXqwbNkyhg8fzvTp07n66qsBmDt3Ltdccw2vv/46hYWFVFZW7lN7zUFBICJNEuU2uY8//pguXbpw4IEHsm7dOubOndvsbQwfPpzHHnsMgOXLlyftcSQaMmQI8+fPZ9OmTVRUVDBnzhxGjBhBeXk57s5Xv/pVbrvtNhYtWkRlZSVlZWWMGjWKu+66i/LycnbUHmfLgLTtNWRmjwBnAhvcfUCt574P3AXkuPvGdNUgIulXNezanHsNpaqgoIB+/foxYMAA+vbty7Bhw5q9je985ztceuml5OfnU1BQwIABA6qHdZLJzc3l9ttvZ+TIkbg7Z511FmeccQaLFi3iyiuvxN0xM37xi19QUVHBJZdcwtatW9m9ezc33XQTXbp0afb30JC0XbPYzE4CtgG/TQwCM/sc8DBwNHBcKkFQWFjoujCNSOasWrWKY445JuoyWoSKigoqKirIzs5m9erVnHrqqaxevZp27VrW3vfJ/mZmVuLuhQ29Nm3vxN0XmFlekqfuAX4APJWutkVEmsu2bdsYPXo0FRUVuDu/+tWvWlwINFVG342ZjQU+dPelDZ0bw8wmAhMBjtCRYCISkW7dulFSUhJ1GWmVsY3FZtYR+BHwk1SWd/cZ7l7o7oU5OQ1ee1lERBopk3sNfR7oAyw1s1IgF1hkZodmsAYREaklY0ND7r4cOLjqcRgGhdprSEQkWmnrEZjZbOAfwFFmVmZmV6arLRERaby0BYG7j3P3w9w9y91z3f3XtZ7PU29ARJIZOXLkXgeHTZs2jW9+85v1vq5z584ArF27lgsuuKDOdTe0O/q0adNqHNh1+umns3nz5lRKr9ett97K1KlTm7ye5qYji0WkxRk3bhxz5sypMW/OnDmMGzcupdcffvjhPP74441uv3YQPPfcc3Tr1q3R62vpFAQi0uJccMEFPPPMM3zyyScAlJaWsnbtWoYPH169X39BQQHHHnssTz219yFJpaWlDBgQHMe6c+dOLr74YvLz87nooovYuXNn9XLXXntt9Smsb7nlFgCmT5/O2rVrOfnkkzn55JMByMvLY+PGYADj7rvvZsCAAQwYMKD6FNalpaUcc8wxfOMb36B///6ceuqpNdpJZsmSJQwZMoT8/HzOPfdc/vOf/1S3369fP/Lz86tPdvfqq69WX5hn8ODBbN26tdGfbTKt66gIEWl23/0uNPeFtwYNgvA7NKkePXpw/PHH88ILL3D22WczZ84cLrroIsyM7OxsnnzySQ488EA2btzIkCFDGDt2bJ3X7X3wwQfp2LEjy5YtY9myZRQUFFQ/N2XKFA466CAqKysZPXo0y5Yt47rrruPuu+9m/vz59OzZs8a6SkpKmDlzJgsXLsTdOeGEExgxYgTdu3dn9erVzJ49m4ceeogLL7yQJ554ot7rC1x66aXcd999jBgxgp/85CfcdtttTJs2jTvuuIP33nuP9u3bVw9HTZ06lQceeIBhw4axbds2srOz9+HTbph6BCLSIiUODyUOC7k7kydPJj8/n1NOOYUPP/yQ9evX17meBQsWVH8h5+fnk5+fX/3cY489RkFBAYMHD2bFihUNnlDutdde49xzz6VTp0507tyZ8847j7/+9a8A9OnTh0GDBgH1n+oagusjbN68mREjRgBw2WWXsWDBguoax48fz6xZs6qPYB42bBg33ngj06dPZ/Pmzc1+ZLN6BCJSr/p+uafTOeecw4033siiRYvYuXNn9S/5oqIiysvLKSkpISsri7y8vKSnnk6UrLfw3nvvMXXqVN544w26d+/O5Zdf3uB66js3W9UprCE4jXVDQ0N1efbZZ1mwYAFPP/00P/3pT1mxYgWTJk3ijDPO4LnnnmPIkCH85S9/4eijj27U+pNRj0BEWqTOnTszcuRIvv71r9fYSLxlyxYOPvhgsrKymD9/Pu8nu0B5gpNOOqn6AvVvvvkmy5YtA4JTWHfq1ImuXbuyfv16nn/++erXdOnSJek4/EknncSf/vQnduzYwfbt23nyySc58cQT9/m9de3ale7du1f3Jn73u98xYsQIdu/ezQcffMDJJ5/MnXfeyebNm9m2bRv/+te/OPbYY7npppsoLCzkrbfe2uc266MegYi0WOPGjeO8886rsQfR+PHjOeussygsLGTQoEEN/jK+9tprueKKK8jPz2fQoEEcf/zxQHC1scGDB9O/f/+9TmE9ceJETjvtNA477DDmz59fPb+goIDLL7+8eh1XXXUVgwcPrncYqC6PPvoo11xzDTt27KBv377MnDmTyspKJkyYwJYtW3B3brjhBrp168aPf/xj5s+fT9u2benXr1/11daaS9pOQ92cdBpqkczSaaj3P005DbWGhkREYk5BICIScwoCEUlqfxg2lkBT/1YKAhHZS3Z2Nps2bVIY7AfcnU2bNjXpIDPtNSQie8nNzaWsrIzy8vKoS5EUZGdnk5ub2+jXKwhEZC9ZWVn06dMn6jIkQzQ0JCIScwoCEZGYUxCIiMScgkBEJObSec3iR8xsg5m9mTDvLjN7y8yWmdmTZtZ6L/kjIrKfSGeP4DfAmFrzXgIGuHs+8E/gh2lsX0REUpDOi9cvAP5da96L7l4RPvxfoPE7voqISLOIchvB14Hn63rSzCaaWbGZFeugFhGR9IkkCMzsR0AFUFTXMu4+w90L3b0wJycnc8WJiMRMxo8sNrPLgDOB0a4TmYiIRC6jQWBmY4CbgBHuviOTbYuISHLp3H10NvAP4CgzKzOzK4H7gS7AS2a2xMz+f7raFxGR1KStR+Du45LM/nW62hMRkcbRkcUiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMpfPi9Y+Y2QYzezNh3kFm9pKZrQ7vu6erfRERSU06ewS/AcbUmjcJeNndvwC8HD4WEZEIpS0I3H0B8O9as88GHg2nHwXOSVf7IiKSmkxvIzjE3dcBhPcH17WgmU00s2IzKy4vL89YgSIicdNiNxa7+wx3L3T3wpycnKjLERFptTIdBOvN7DCA8H5DhtsXEZFaMh0ETwOXhdOXAU9luH0REaklnbuPzgb+ARxlZmVmdiVwB/BlM1sNfDl8LCIiEWqXrhW7+7g6nhqdrjZFRGTftdiNxSIikhkKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYiyQIzOwGM1thZm+a2Wwzy46iDhERiSAIzKwXcB1Q6O4DgLbAxZmuQ0REAikFgZl93szah9Mjzew6M+vWhHbbAR3MrB3QEVjbhHWJiEgTpNojeAKoNLMjgV8DfYDfN6ZBd/8QmAqsAdYBW9z9xcasS0REmi7VINjt7hXAucA0d78BOKwxDZpZd+BsgjA5HOhkZhOSLDfRzIrNrLi8vLwxTYmISApSDYLPzGwccBnwTDgvq5FtngK85+7l7v4Z8EfgS7UXcvcZ7l7o7oU5OTmNbEpERBqSahBcAQwFprj7e2bWB5jVyDbXAEPMrKOZGTAaWNXIdYmISBO1S2Uhd19JsKdP1dBOF3e/ozENuvtCM3scWARUAIuBGY1Zl4iINF1KQWBmrwBjw+WXAOVm9qq739iYRt39FuCWxrxWRESaV6pDQ13d/WPgPGCmux9HMNYvIiL7uVSDoJ2ZHQZcyJ6NxSIi0gqkGgS3A3OBf7n7G2bWF1idvrJERCRTUt1Y/D/A/yQ8fhc4P11FiYhI5qR6iolcM3vSzDaY2Xoze8LMctNdnIiIpF+qQ0MzgacJjgTuBfw5nCciIvu5VIMgx91nuntFePsNoMN9RURagVSDYKOZTTCztuFtArApnYWJiEhmpBoEXyfYdfQjgjOGXkBw2gkREdnPpRQE7r7G3ce6e467H+zu5xAcXCYiIvu5plyhrFGnlxARkZalKUFgzVaFiIhEpilB4M1WhYiIRKbeI4vNbCvJv/AN6JCWikREJKPqDQJ375KpQkREJBpNGRoSEZFWQEEgIhJzCgIRkZhTEIiIxFwkQWBm3czscTN7y8xWmdnQKOoQEZEUL0yTBvcCL7j7BWZ2ANAxojpERGIv40FgZgcCJwGXA7j7p8Cnma5DREQCUQwN9QXKgZlmttjMHjazTrUXMrOJZlZsZsXl5eWZr1JEJCaiCIJ2QAHwoLsPBrYDk2ov5O4z3L3Q3QtzcnQNHBGRdIkiCMqAMndfGD5+nCAYREQkAhkPAnf/CPjAzI4KZ40GVma6DhERCUS119B3gKJwj6F30dXOREQiE0kQuPsSoDCKtkVEpCYdWSwiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCIiMRcZEFgZm3NbLGZPRNVDSIiEm2P4HpgVYTti4gIEQWBmeUCZwAPR9G+iIjsEVWPYBrwA2B3XQuY2UQzKzaz4vLy8sxVJiISMxkPAjM7E9jg7iX1LefuM9y90N0Lc3JyMlSdiEj8RNEjGAaMNbNSYA4wysxmRVCHiIgQQRC4+w/dPdfd84CLgXnuPiHTdYiISEDHEYiIxFy7KBt391eAV6KsQUQk7tQjEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMxlPAjM7HNmNt/MVpnZCjO7PtM1iIjIHlFcs7gC+J67LzKzLkCJmb3k7isjqEVEJPYy3iNw93Xuviic3gqsAnplug4REQlEuo3AzPKAwcDCJM9NNLNiMysuLy/PdGkiIrERWRCYWWfgCeC77v5x7efdfYa7F7p7YU5OTuYLFBGJiUiCwMyyCEKgyN3/GEUNIiISiGKvIQN+Daxy97sz3b6IiNQURY9gGPA1YJSZLQlvp0dQh4iIEMHuo+7+GmCZbldERJLTkcUiIjGnIBARiblWHQRvvQXLloF71JWIiLRcrToI7roLBg6EI46Aq6+Gp56CbdsyW0NREeTlQZs2wX1RUWbbFxFpiPl+8HO5sLDQi4uL9/l1a9fCCy/Ac8/Biy/C1q1wwAFw0klw+unB7b/+CyxNm66LimDiRNixY8+8jh1hxgwYPz49bYqIVDGzEncvbHC51hwEiT79FP72tyAUnnsOVoanuOvbF844IwiFESOgQ4dmKDiUlwfvv7/3/N69obS0+doREUlGQdCA0tI9oTBvHuzcGYTAqFF7egt5eU1ro02b5NsnzGD37qatW0SkIQqCfbBzJ7z6ahAKzz4L774bzO/Xb08oDBsWDCvtC/UIRCRKqQZBq95YnKoOHWDMGJg+Hd55J9jb6O674fDD4d57g15Cz55w/vnwyCPBtodUTJkSbBNI1LFjMD/TtNFaROqiHkEDtm4Nho6efTboMXz4YTB/8OA9vYUTToC2bZO/vqgIfvQjWLMm2HtpypTMbyjWRmuReNLQUBq4w/Lle7Yt/P3vUFkJBx0EX/lKsNH5K18Jeg8tiYaoROJJQ0NpYAb5+TBpEixYAOXlMGcOnHkm/OUvMGECHHwwDB0KP/0plJS0jI3Ca9bs2/x00hCVSMujHkEz2b07+OKv6i288UbQgzj0UDjtNBg0CDp1CoZkkt0Sn2vfvnmPbUh3j8AdPvssGHravj24TzY9bx48+miwbJX27eEXvwgO+MvObnotqWgJw3UimaChoYht2LDnYLa5c2Hz5tRfa5Y8IOoLj/qee/XV4Mtu1649bbRvDzfeCF/6UsNf4KlMV1Y2/TPr2hUOOSQIz8T72vMOPjiovzFa0vaSlhJIqqP1UhC0IJWVQRBUfXHW/iKtfavvuWTPb9/e/ENQHTokD5WmTB9zTN3tTZkCH30E69fXvN+yJfny3bo1HBiHHBKERuJuv5noHX3ySRC69d2/8ALcd19woGOVAw6Aa6+FU06BrKzG3/alN9lSgrGl1FFVS0sIpKIimDw5qKN378bVoSCIkbqGZpIFSFZW3T2HqukOHYIx/ObWmC/hXbuC3lWykFi/vub0x3td+Tpw0EF7guKVV+qu75Zb6v8Cb+jLfdeuml/sUWnbNvg7t2vXcGgsXx7UXluHDkEgtWkT3Mzqn27q87/8ZfK/X9eucMMNe8LNrOZ0snkNPV/fa0pKgu1+icOXWVkwdmxwXFFFRfBcRUXN6eae98knwX2ixgSjgkBanHT/6tu5s+6QqLpfuHDv/2CJsrKCbRXZ2cHwU7L75njuxBPrruH114MvhOa4VX251HV7/vm66xg0KOhpute8r2u6Kc+3hABNRWLAtmtXczrZvIaer2veQw8lD8Z97bkqCKRFirrbnSyMOnSABx6Ayy5LT08omZayS29Lr+OII+C994Jp9z2nbEm8r2u6Ma/p0aPuGnfvTt8JKmtrrtPTpBoEuHuLvx133HEu0lxmzXLv3dvdLLifNSuaGjp2rPoaCm4dO2a+FtVRU+/eNWuouvXuvX/WARR7Ct+xkXyxA2OAt4F3gEkNLa8gkNaoJQSS6ti7hpYQSM1VR6pBkPGhITNrC/wT+DJQBrwBjHP3lXW9RkNDIpIpUQ9fNmcdLXYbgZkNBW5196+Ej38I4O4/r+s1CgIRkX3Xkk8x0Qv4IOFxWTivBjObaGbFZlZcXl6eseJEROImiiBItt19r26Ju89w90J3L8zJyclAWSIi8RRFEJQBn0t4nAukeIZ/ERFpblEEwRvAF8ysj5kdAFwMPB1BHSIiArTLdIPuXmFm3wbmAm2BR9x9RabrEBGRwH5xZLGZlQNJjjvcr/QENkZdRAuiz2MPfRY16fOoqSmfR293b3Aj634RBK2BmRWnshtXXOjz2EOfRU36PGrKxOehK5SJiMScgkBEJOYUBJkzI+oCWhh9Hnvos6hJn0dNaf88tI1ARCTm1CMQEYk5BYGISMwpCNLMzD5nZvPNbJWZrTCz66OuKWpm1tbMFpvZM1HXEjUz62Zmj5vZW+G/kaFR1xQVM7sh/D/yppnNNrPsqGvKJDN7xMw2mNmbCfMOMrOXzGx1eN89HW0rCNKvAvieux8DDAG+ZWb9Iq4patcDq6IuooW4F3jB3Y8GBhLTz8XMegHXAYXuPoDgrAMXR1tVxv2G4KJdiSYBL7v7F4CXw8fNTkGQZu6+zt0XhdNbCf6j73Xa7bgws1zgDODhqGuJmpkdCJwE/BrA3T91983RVhWpdkAHM2sHdCRmJ6N09wXAv2vNPht4NJwSwq92AAADTUlEQVR+FDgnHW0rCDLIzPKAwcDCaCuJ1DTgB8A+XIK71eoLlAMzw6Gyh82sU9RFRcHdPwSmAmuAdcAWd38x2qpahEPcfR0EPyqBg9PRiIIgQ8ysM/AE8F13/zjqeqJgZmcCG9y9JOpaWoh2QAHwoLsPBraTpq5/SxeOfZ8N9AEOBzqZ2YRoq4oPBUEGmFkWQQgUufsfo64nQsOAsWZWCswBRpnZrGhLilQZUObuVT3ExwmCIY5OAd5z93J3/wz4I/CliGtqCdab2WEA4f2GdDSiIEgzMzOCMeBV7n531PVEyd1/6O657p5HsCFwnrvH9lefu38EfGBmR4WzRgMrIywpSmuAIWbWMfw/M5qYbjiv5WngsnD6MuCpdDSS8esRxNAw4GvAcjNbEs6b7O7PRViTtBzfAYrCizS9C1wRcT2RcPeFZvY4sIhgT7vFxOxUE2Y2GxgJ9DSzMuAW4A7gMTO7kiAsv5qWtnWKCRGReNPQkIhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQGLNzCrNbEnCrdmO7DWzvMQzSYq0VDqOQOJup7sPiroIkSipRyCShJmVmtkvzOz18HZkOL+3mb1sZsvC+yPC+YeY2ZNmtjS8VZ0eoa2ZPRSeZ/9FM+sQLn+dma0M1zMnorcpAigIRDrUGhq6KOG5j939eOB+grOmEk7/1t3zgSJgejh/OvCquw8kOF/QinD+F4AH3L0/sBk4P5w/CRgcrueadL05kVToyGKJNTPb5u6dk8wvBUa5+7vhSQM/cvceZrYROMzdPwvnr3P3nmZWDuS6+ycJ68gDXgovKoKZ3QRkufvPzOwFYBvwJ+BP7r4tzW9VpE7qEYjUzeuYrmuZZD5JmK5kz3a5M4AHgOOAkvBiLCKRUBCI1O2ihPt/hNN/Z88lFMcDr4XTLwPXQvU1mQ+sa6Vm1gb4nLvPJ7hITzdgr16JSKboV4jEXYeEs8JCcP3gql1I25vZQoIfTOPCedcBj5jZfxNcXazqbKHXAzPCs0RWEoTCujrabAvMMrOugAH3xPwSlRIxbSMQSSLcRlDo7hujrkUk3TQ0JCISc+oRiIjEnHoEIiIxpyAQEYk5BYGISMwpCEREYk5BICISc/8HTwmTjLc90voAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, it looks like that it begins to overfit around 6th epoch. <br>\n",
    "So we are going to retrain the model from scratch and try to predict the for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here it look like that even 10 might not be a bad choice to limit it for overfitting. \n",
    "\n",
    "So we are taking 10 as the number of epoch for the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Retraining the model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are training the whole model from begining here\n",
    "\n",
    "model1 = models.Sequential() #sequential models\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,))) # 512 features are created from the input ones\n",
    "model1.add(layers.Dense(256, activation='relu', input_shape=(28 * 28,))) #\n",
    "model1.add(layers.Dense(128, activation='relu', input_shape=(28 * 28,))) #\n",
    "model1.add(layers.Dense(64, activation='relu', input_shape=(28 * 28,))) # \n",
    "model1.add(layers.Dense(10, activation='softmax')) #This is the final layer that has ten categories who probabilties add to 1.\n",
    "\n",
    "\n",
    "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/11\n",
      "48000/48000 [==============================] - 15s 308us/step - loss: 16.2703 - accuracy: 0.5588 - val_loss: 1.6409 - val_accuracy: 0.6595\n",
      "Epoch 2/11\n",
      "48000/48000 [==============================] - 12s 258us/step - loss: 1.4499 - accuracy: 0.6886 - val_loss: 0.6678 - val_accuracy: 0.7563\n",
      "Epoch 3/11\n",
      "48000/48000 [==============================] - 11s 227us/step - loss: 0.8294 - accuracy: 0.7467 - val_loss: 0.5599 - val_accuracy: 0.7903\n",
      "Epoch 4/11\n",
      "48000/48000 [==============================] - 11s 225us/step - loss: 0.6071 - accuracy: 0.7921 - val_loss: 0.5709 - val_accuracy: 0.7905\n",
      "Epoch 5/11\n",
      "48000/48000 [==============================] - 11s 230us/step - loss: 0.5530 - accuracy: 0.8090 - val_loss: 0.6651 - val_accuracy: 0.7721\n",
      "Epoch 6/11\n",
      "48000/48000 [==============================] - 12s 243us/step - loss: 0.4600 - accuracy: 0.8347 - val_loss: 0.4600 - val_accuracy: 0.8335\n",
      "Epoch 7/11\n",
      "48000/48000 [==============================] - 14s 301us/step - loss: 0.4320 - accuracy: 0.8429 - val_loss: 0.6095 - val_accuracy: 0.8082\n",
      "Epoch 8/11\n",
      "48000/48000 [==============================] - 14s 283us/step - loss: 0.3991 - accuracy: 0.8528 - val_loss: 0.4515 - val_accuracy: 0.8447\n",
      "Epoch 9/11\n",
      "48000/48000 [==============================] - 13s 263us/step - loss: 0.3764 - accuracy: 0.8618 - val_loss: 0.4855 - val_accuracy: 0.8288\n",
      "Epoch 10/11\n",
      "48000/48000 [==============================] - 11s 232us/step - loss: 0.3659 - accuracy: 0.8651 - val_loss: 0.3878 - val_accuracy: 0.8603\n",
      "Epoch 11/11\n",
      "48000/48000 [==============================] - 12s 242us/step - loss: 0.3513 - accuracy: 0.8713 - val_loss: 0.4267 - val_accuracy: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f439684710>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train_partial_cnn,\n",
    "            y_train_partial_cnn,\n",
    "            epochs=11,\n",
    "            batch_size=512,\n",
    "            validation_data=(x_val_cnn, y_val_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 259us/step\n"
     ]
    }
   ],
   "source": [
    "results = model1.evaluate(test_images_cnn, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48003657822608947, 0.8458999991416931]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen above the accuracy is about 88%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline CNN model.\n",
    "\n",
    "* In this we have fit the baseline CNN model\n",
    "* We have modified the parameters to the best of our intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the cnn model\n",
    "model_cnn = models.Sequential() # The different layers will be added in a seqeunce\n",
    "\n",
    "# Adding a convulusion layer\n",
    "model_cnn.add(Convolution2D(15,3, 3, input_shape=(28, 28,1), activation='relu',border_mode= 'same'))\n",
    "#Pooling layer to donsize the data extract maximum in the filter \n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "# Dropout to fight overfitting\n",
    "model_cnn.add(Dropout(0.2))\n",
    "#Another pooling layer with 64 filters this time. Relu activation to make sure no value is negative\n",
    "model_cnn.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "#Another pooling layer with same padding\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "#naother dropout layer to combat overfitting.\n",
    "model_cnn.add(Dropout(0.1))\n",
    "          \n",
    "# Creating a regular neural network\n",
    "model_cnn.add(Flatten()) # Flattens the output from cnn for nn\n",
    "model_cnn.add(Dense(256, activation='relu')) #regular hiddden layer with 256 nodes\n",
    "model_cnn.add(Dense(128, activation='relu')) #regular hiddden layer with 128 nodes\n",
    "          \n",
    "# Final output layer with ten nodes, one for each category\n",
    "model_cnn.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 135s 3ms/step - loss: 0.9173 - accuracy: 0.7870 - val_loss: 0.3997 - val_accuracy: 0.8648\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 140s 3ms/step - loss: 0.3763 - accuracy: 0.8621 - val_loss: 0.3368 - val_accuracy: 0.8770\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 126s 3ms/step - loss: 0.3275 - accuracy: 0.8786 - val_loss: 0.2893 - val_accuracy: 0.8933\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 124s 3ms/step - loss: 0.2918 - accuracy: 0.8905 - val_loss: 0.2819 - val_accuracy: 0.8988\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 125s 3ms/step - loss: 0.2718 - accuracy: 0.9004 - val_loss: 0.2642 - val_accuracy: 0.9056\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 126s 3ms/step - loss: 0.2571 - accuracy: 0.9040 - val_loss: 0.2438 - val_accuracy: 0.9106\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 124s 3ms/step - loss: 0.2410 - accuracy: 0.9092 - val_loss: 0.2409 - val_accuracy: 0.9121\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 124s 3ms/step - loss: 0.2285 - accuracy: 0.9139 - val_loss: 0.2417 - val_accuracy: 0.9107\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 123s 3ms/step - loss: 0.2198 - accuracy: 0.9174 - val_loss: 0.2373 - val_accuracy: 0.9111\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 121s 3ms/step - loss: 0.2035 - accuracy: 0.9222 - val_loss: 0.2535 - val_accuracy: 0.9094\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history =    model_cnn.fit(x_train_partial_cnn,\n",
    "             y_train_partial_cnn,\n",
    "             batch_size=64,\n",
    "             epochs=10,\n",
    "             validation_data=(x_val_cnn, y_val_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 827us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss_cnn, test_acc_cnn = model_cnn.evaluate(test_images_cnn, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9032999873161316"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Standarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is cleaned/standarised using the Image data Generattor. Many different functions can be applied in the same generator.\n",
    "* <b> feature_wise_center, feature_wise_std_normalization </b> -  This centers and scales the image\n",
    "* <b> rescale </b> - This converts all the pixels value in the range (0,1). A lot of blogs suggest that NN likes small inputs.\n",
    "* <b> zca whitening </b> - This emphasized the pixels that have some objects. Its sort of cousin to PCA.\n",
    "* <b> rotation_range </b> - Rotates the images in the mentioned range (Max).\n",
    "* <b> Horizontal/Vertical Flip </b>  - Flips the image around the axis.\n",
    "\n",
    "Then the generator is fit into the model, pretty much similar to fitting the data. In this case 'class_mode' arguement is not working. The probable issue is the version of TF. But its fine without that as well.\n",
    "\n",
    "Should discuss with Prof.Dave how much epochs to run for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_cnn = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True,rescale=1./255,\n",
    "                             zca_whitening=True, rotation_range=90,horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "test_datagen_cnn = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#, class_mode='categorical'\n",
    "\n",
    "train_generator_cnn = train_datagen_cnn.flow(x_train_partial_cnn, y_train_partial_cnn)\n",
    "validation_generator_cnn = test_datagen_cnn.flow(x_val_cnn, y_val_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "420/420 [==============================] - 57s 135ms/step - loss: 0.5635 - accuracy: 0.7940 - val_loss: 0.6155 - val_accuracy: 0.8077\n",
      "Epoch 2/60\n",
      "420/420 [==============================] - 54s 129ms/step - loss: 0.5677 - accuracy: 0.7870 - val_loss: 0.6677 - val_accuracy: 0.8151\n",
      "Epoch 3/60\n",
      "420/420 [==============================] - 54s 129ms/step - loss: 0.5575 - accuracy: 0.7971 - val_loss: 0.4467 - val_accuracy: 0.8166\n",
      "Epoch 4/60\n",
      "420/420 [==============================] - 54s 128ms/step - loss: 0.5576 - accuracy: 0.7933 - val_loss: 0.4804 - val_accuracy: 0.8064\n",
      "Epoch 5/60\n",
      "420/420 [==============================] - 54s 130ms/step - loss: 0.5673 - accuracy: 0.7935 - val_loss: 0.5755 - val_accuracy: 0.8061\n",
      "Epoch 6/60\n",
      "420/420 [==============================] - 54s 128ms/step - loss: 0.5521 - accuracy: 0.7946 - val_loss: 0.5189 - val_accuracy: 0.8264\n",
      "Epoch 7/60\n",
      "420/420 [==============================] - 54s 129ms/step - loss: 0.5612 - accuracy: 0.7946 - val_loss: 0.3445 - val_accuracy: 0.8137\n",
      "Epoch 8/60\n",
      "420/420 [==============================] - 55s 130ms/step - loss: 0.5616 - accuracy: 0.7899 - val_loss: 0.4417 - val_accuracy: 0.8287\n",
      "Epoch 9/60\n",
      "420/420 [==============================] - 60s 144ms/step - loss: 0.5505 - accuracy: 0.7991 - val_loss: 0.4831 - val_accuracy: 0.8231\n",
      "Epoch 10/60\n",
      "420/420 [==============================] - 60s 142ms/step - loss: 0.5477 - accuracy: 0.7949 - val_loss: 0.7437 - val_accuracy: 0.8200\n",
      "Epoch 11/60\n",
      "420/420 [==============================] - 53s 127ms/step - loss: 0.5410 - accuracy: 0.8025 - val_loss: 0.3532 - val_accuracy: 0.8273\n",
      "Epoch 12/60\n",
      "420/420 [==============================] - 70s 166ms/step - loss: 0.5437 - accuracy: 0.7982 - val_loss: 0.6089 - val_accuracy: 0.8228\n",
      "Epoch 13/60\n",
      "420/420 [==============================] - 64s 153ms/step - loss: 0.5490 - accuracy: 0.7987 - val_loss: 0.4811 - val_accuracy: 0.8140\n",
      "Epoch 14/60\n",
      "420/420 [==============================] - 58s 138ms/step - loss: 0.5343 - accuracy: 0.8026 - val_loss: 0.6831 - val_accuracy: 0.8058\n",
      "Epoch 15/60\n",
      "420/420 [==============================] - 53s 127ms/step - loss: 0.5269 - accuracy: 0.8052 - val_loss: 0.3577 - val_accuracy: 0.8295\n",
      "Epoch 16/60\n",
      "420/420 [==============================] - 54s 130ms/step - loss: 0.5425 - accuracy: 0.7977 - val_loss: 0.5219 - val_accuracy: 0.8198\n",
      "Epoch 17/60\n",
      "420/420 [==============================] - 55s 131ms/step - loss: 0.5322 - accuracy: 0.8031 - val_loss: 0.8538 - val_accuracy: 0.8228\n",
      "Epoch 18/60\n",
      "420/420 [==============================] - 55s 131ms/step - loss: 0.5487 - accuracy: 0.8004 - val_loss: 0.6146 - val_accuracy: 0.8261\n",
      "Epoch 19/60\n",
      "420/420 [==============================] - 55s 131ms/step - loss: 0.5378 - accuracy: 0.8012 - val_loss: 0.7032 - val_accuracy: 0.8238\n",
      "Epoch 20/60\n",
      "420/420 [==============================] - 54s 129ms/step - loss: 0.5294 - accuracy: 0.8068 - val_loss: 0.2848 - val_accuracy: 0.8253\n",
      "Epoch 21/60\n",
      "420/420 [==============================] - 55s 131ms/step - loss: 0.5413 - accuracy: 0.7991 - val_loss: 0.3755 - val_accuracy: 0.8341\n",
      "Epoch 22/60\n",
      "420/420 [==============================] - 54s 129ms/step - loss: 0.5053 - accuracy: 0.8179 - val_loss: 0.4045 - val_accuracy: 0.8141\n",
      "Epoch 23/60\n",
      "420/420 [==============================] - 53s 126ms/step - loss: 0.5394 - accuracy: 0.8009 - val_loss: 0.4234 - val_accuracy: 0.8068\n",
      "Epoch 24/60\n",
      "420/420 [==============================] - 59s 140ms/step - loss: 0.5282 - accuracy: 0.8116 - val_loss: 0.2904 - val_accuracy: 0.8387\n",
      "Epoch 25/60\n",
      "420/420 [==============================] - 59s 142ms/step - loss: 0.5375 - accuracy: 0.8031 - val_loss: 0.3745 - val_accuracy: 0.8322\n",
      "Epoch 26/60\n",
      "420/420 [==============================] - 64s 152ms/step - loss: 0.5393 - accuracy: 0.8031 - val_loss: 0.5834 - val_accuracy: 0.8308\n",
      "Epoch 27/60\n",
      "420/420 [==============================] - 69s 164ms/step - loss: 0.5099 - accuracy: 0.8126 - val_loss: 0.4742 - val_accuracy: 0.8289\n",
      "Epoch 28/60\n",
      "420/420 [==============================] - 67s 159ms/step - loss: 0.5324 - accuracy: 0.8027 - val_loss: 0.5142 - val_accuracy: 0.8307\n",
      "Epoch 29/60\n",
      "420/420 [==============================] - 57s 135ms/step - loss: 0.5113 - accuracy: 0.8108 - val_loss: 0.2727 - val_accuracy: 0.8264\n",
      "Epoch 30/60\n",
      "420/420 [==============================] - 49s 118ms/step - loss: 0.5336 - accuracy: 0.8048 - val_loss: 0.2561 - val_accuracy: 0.8223\n",
      "Epoch 31/60\n",
      "420/420 [==============================] - 55s 130ms/step - loss: 0.5178 - accuracy: 0.8100 - val_loss: 0.7856 - val_accuracy: 0.8289\n",
      "Epoch 32/60\n",
      "420/420 [==============================] - 48s 114ms/step - loss: 0.5133 - accuracy: 0.8106 - val_loss: 0.4719 - val_accuracy: 0.8296\n",
      "Epoch 33/60\n",
      "420/420 [==============================] - 61s 146ms/step - loss: 0.5092 - accuracy: 0.8126 - val_loss: 0.4447 - val_accuracy: 0.8335\n",
      "Epoch 34/60\n",
      "420/420 [==============================] - 67s 159ms/step - loss: 0.5204 - accuracy: 0.8057 - val_loss: 0.2304 - val_accuracy: 0.8299\n",
      "Epoch 35/60\n",
      "420/420 [==============================] - 63s 150ms/step - loss: 0.5260 - accuracy: 0.8090 - val_loss: 0.4634 - val_accuracy: 0.8232\n",
      "Epoch 36/60\n",
      "420/420 [==============================] - 58s 139ms/step - loss: 0.5160 - accuracy: 0.8101 - val_loss: 0.4505 - val_accuracy: 0.8313\n",
      "Epoch 37/60\n",
      "420/420 [==============================] - 48s 114ms/step - loss: 0.5194 - accuracy: 0.8068 - val_loss: 0.5659 - val_accuracy: 0.8167\n",
      "Epoch 38/60\n",
      "420/420 [==============================] - 49s 116ms/step - loss: 0.5234 - accuracy: 0.8087 - val_loss: 0.3850 - val_accuracy: 0.8303\n",
      "Epoch 39/60\n",
      "420/420 [==============================] - 48s 115ms/step - loss: 0.5114 - accuracy: 0.8134 - val_loss: 0.4693 - val_accuracy: 0.8292\n",
      "Epoch 40/60\n",
      "420/420 [==============================] - 48s 114ms/step - loss: 0.4860 - accuracy: 0.8190 - val_loss: 0.5094 - val_accuracy: 0.8278\n",
      "Epoch 41/60\n",
      "420/420 [==============================] - 49s 117ms/step - loss: 0.5232 - accuracy: 0.8060 - val_loss: 0.4967 - val_accuracy: 0.8328\n",
      "Epoch 42/60\n",
      "420/420 [==============================] - 48s 115ms/step - loss: 0.5113 - accuracy: 0.8125 - val_loss: 0.4507 - val_accuracy: 0.8439\n",
      "Epoch 43/60\n",
      "420/420 [==============================] - 48s 115ms/step - loss: 0.5117 - accuracy: 0.8129 - val_loss: 0.5185 - val_accuracy: 0.8307\n",
      "Epoch 44/60\n",
      "420/420 [==============================] - 48s 115ms/step - loss: 0.5114 - accuracy: 0.8092 - val_loss: 0.2296 - val_accuracy: 0.8409\n",
      "Epoch 45/60\n",
      "420/420 [==============================] - 66s 157ms/step - loss: 0.5121 - accuracy: 0.8121 - val_loss: 0.4724 - val_accuracy: 0.8169\n",
      "Epoch 46/60\n",
      "420/420 [==============================] - 54s 128ms/step - loss: 0.5071 - accuracy: 0.8147 - val_loss: 0.5085 - val_accuracy: 0.8435\n",
      "Epoch 47/60\n",
      "420/420 [==============================] - 53s 126ms/step - loss: 0.5104 - accuracy: 0.8103 - val_loss: 0.4601 - val_accuracy: 0.8372\n",
      "Epoch 48/60\n",
      "420/420 [==============================] - 57s 135ms/step - loss: 0.5082 - accuracy: 0.8133 - val_loss: 0.4707 - val_accuracy: 0.8407\n",
      "Epoch 49/60\n",
      "420/420 [==============================] - 58s 138ms/step - loss: 0.5063 - accuracy: 0.8103 - val_loss: 0.4153 - val_accuracy: 0.8381\n",
      "Epoch 50/60\n",
      "420/420 [==============================] - 69s 165ms/step - loss: 0.4964 - accuracy: 0.8205 - val_loss: 0.6134 - val_accuracy: 0.8429\n",
      "Epoch 51/60\n",
      "420/420 [==============================] - 82s 196ms/step - loss: 0.4854 - accuracy: 0.8217 - val_loss: 0.3081 - val_accuracy: 0.8393\n",
      "Epoch 52/60\n",
      "420/420 [==============================] - 74s 176ms/step - loss: 0.5073 - accuracy: 0.8152 - val_loss: 0.7995 - val_accuracy: 0.8419\n",
      "Epoch 53/60\n",
      "420/420 [==============================] - 64s 153ms/step - loss: 0.5065 - accuracy: 0.8116 - val_loss: 0.2155 - val_accuracy: 0.8383\n",
      "Epoch 54/60\n",
      "420/420 [==============================] - 70s 166ms/step - loss: 0.5072 - accuracy: 0.8125 - val_loss: 0.5806 - val_accuracy: 0.8301\n",
      "Epoch 55/60\n",
      "420/420 [==============================] - 70s 167ms/step - loss: 0.4983 - accuracy: 0.8173 - val_loss: 0.5393 - val_accuracy: 0.8357\n",
      "Epoch 56/60\n",
      "420/420 [==============================] - 71s 169ms/step - loss: 0.4994 - accuracy: 0.8170 - val_loss: 0.4088 - val_accuracy: 0.8355\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 79s 188ms/step - loss: 0.5018 - accuracy: 0.8155 - val_loss: 0.3470 - val_accuracy: 0.8336\n",
      "Epoch 58/60\n",
      "420/420 [==============================] - 71s 169ms/step - loss: 0.5071 - accuracy: 0.8144 - val_loss: 0.3663 - val_accuracy: 0.8407\n",
      "Epoch 59/60\n",
      "420/420 [==============================] - 59s 141ms/step - loss: 0.4958 - accuracy: 0.8129 - val_loss: 0.5775 - val_accuracy: 0.8338\n",
      "Epoch 60/60\n",
      "420/420 [==============================] - 56s 134ms/step - loss: 0.4903 - accuracy: 0.8194 - val_loss: 0.6626 - val_accuracy: 0.8221\n",
      "Wall time: 58min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f426adb828>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_cnn.fit_generator(train_generator_cnn, steps_per_epoch=420,epochs=60, validation_data=validation_generator_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model after pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am scaling the images in this.\n",
    "# Because when I did without scaling, the results were awful\n",
    "# This is probably because the network has been trained for that scale\n",
    "test_images_cnn_1 = test_images_cnn.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 828us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5608284721851349, 0.7961999773979187]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the results on model trained on standarised samples\n",
    "model_cnn.evaluate(test_images_cnn_1,test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7961999773979187"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_cnn\n",
    "\n",
    "# The current training of the model is roughly equal to two epochs of normal cnn\n",
    "# Thus if we train it for more epochs, this should improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 1.4197 - accuracy: 0.4665 - val_loss: 0.9640 - val_accuracy: 0.5936\n",
      "Epoch 2/30\n",
      "420/420 [==============================] - 20s 48ms/step - loss: 1.0918 - accuracy: 0.5911 - val_loss: 0.7033 - val_accuracy: 0.6833\n",
      "Epoch 3/30\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 1.0143 - accuracy: 0.6255 - val_loss: 0.6299 - val_accuracy: 0.6658\n",
      "Epoch 4/30\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.9615 - accuracy: 0.6397 - val_loss: 1.0365 - val_accuracy: 0.7022\n",
      "Epoch 5/30\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.9414 - accuracy: 0.6469 - val_loss: 0.4070 - val_accuracy: 0.7407\n",
      "Epoch 6/30\n",
      "420/420 [==============================] - 20s 49ms/step - loss: 0.9103 - accuracy: 0.6648 - val_loss: 0.5647 - val_accuracy: 0.7356\n",
      "Epoch 7/30\n",
      "420/420 [==============================] - 17s 41ms/step - loss: 0.8820 - accuracy: 0.6741 - val_loss: 0.6701 - val_accuracy: 0.7125\n",
      "Epoch 8/30\n",
      "420/420 [==============================] - 21s 49ms/step - loss: 0.8656 - accuracy: 0.6771 - val_loss: 0.6419 - val_accuracy: 0.7146\n",
      "Epoch 9/30\n",
      "420/420 [==============================] - 21s 50ms/step - loss: 0.8608 - accuracy: 0.6899 - val_loss: 0.9655 - val_accuracy: 0.7436\n",
      "Epoch 10/30\n",
      "420/420 [==============================] - 20s 48ms/step - loss: 0.8605 - accuracy: 0.6882 - val_loss: 0.5442 - val_accuracy: 0.7362\n",
      "Epoch 11/30\n",
      "420/420 [==============================] - 24s 56ms/step - loss: 0.8390 - accuracy: 0.6938 - val_loss: 0.6356 - val_accuracy: 0.7168\n",
      "Epoch 12/30\n",
      "420/420 [==============================] - 25s 58ms/step - loss: 0.8437 - accuracy: 0.6985 - val_loss: 0.5563 - val_accuracy: 0.7614\n",
      "Epoch 13/30\n",
      "420/420 [==============================] - 20s 47ms/step - loss: 0.8279 - accuracy: 0.7079 - val_loss: 0.6371 - val_accuracy: 0.7425\n",
      "Epoch 14/30\n",
      "420/420 [==============================] - 20s 48ms/step - loss: 0.8308 - accuracy: 0.6998 - val_loss: 0.6186 - val_accuracy: 0.7348\n",
      "Epoch 15/30\n",
      "420/420 [==============================] - 20s 47ms/step - loss: 0.8406 - accuracy: 0.7010 - val_loss: 1.0636 - val_accuracy: 0.7583\n",
      "Epoch 16/30\n",
      "420/420 [==============================] - 20s 48ms/step - loss: 0.8330 - accuracy: 0.7089 - val_loss: 0.4565 - val_accuracy: 0.7723\n",
      "Epoch 17/30\n",
      "420/420 [==============================] - 21s 51ms/step - loss: 0.8121 - accuracy: 0.7131 - val_loss: 1.2250 - val_accuracy: 0.7090\n",
      "Epoch 18/30\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 0.8388 - accuracy: 0.7094 - val_loss: 0.8203 - val_accuracy: 0.7396\n",
      "Epoch 19/30\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 0.8259 - accuracy: 0.7067 - val_loss: 1.2337 - val_accuracy: 0.7623\n",
      "Epoch 20/30\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.8160 - accuracy: 0.7115 - val_loss: 0.9766 - val_accuracy: 0.7360\n",
      "Epoch 21/30\n",
      "420/420 [==============================] - 19s 46ms/step - loss: 0.8289 - accuracy: 0.7161 - val_loss: 0.7936 - val_accuracy: 0.7547\n",
      "Epoch 22/30\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.8376 - accuracy: 0.7097 - val_loss: 1.8823 - val_accuracy: 0.7136\n",
      "Epoch 23/30\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.8196 - accuracy: 0.7185 - val_loss: 0.8332 - val_accuracy: 0.7320\n",
      "Epoch 24/30\n",
      "420/420 [==============================] - 18s 44ms/step - loss: 0.8268 - accuracy: 0.7174 - val_loss: 0.8653 - val_accuracy: 0.7620\n",
      "Epoch 25/30\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.8195 - accuracy: 0.7172 - val_loss: 0.6305 - val_accuracy: 0.7801\n",
      "Epoch 26/30\n",
      "420/420 [==============================] - 18s 43ms/step - loss: 0.8261 - accuracy: 0.7100 - val_loss: 0.6960 - val_accuracy: 0.7658\n",
      "Epoch 27/30\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 0.8125 - accuracy: 0.7282 - val_loss: 0.5151 - val_accuracy: 0.7685\n",
      "Epoch 28/30\n",
      "420/420 [==============================] - 19s 45ms/step - loss: 0.8426 - accuracy: 0.7145 - val_loss: 0.5718 - val_accuracy: 0.7440\n",
      "Epoch 29/30\n",
      "420/420 [==============================] - 17s 40ms/step - loss: 0.8438 - accuracy: 0.7147 - val_loss: 0.7884 - val_accuracy: 0.7838\n",
      "Epoch 30/30\n",
      "420/420 [==============================] - 19s 46ms/step - loss: 0.8239 - accuracy: 0.7242 - val_loss: 0.5866 - val_accuracy: 0.7577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f42fc69940>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the mlp with the generator that creates randomness in the images. \n",
    "\n",
    "model1.fit_generator(train_generator_cnn, steps_per_epoch=420,epochs=30, validation_data=validation_generator_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 257us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.698199987411499"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss_mlp, test_acc_mlp = model1.evaluate(test_images_cnn, test_labels)\n",
    "test_acc_mlp\n",
    "\n",
    "# This is just equivalent to one epoch if that is increased this should also go up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the things we observed:\n",
    "\n",
    "The dataset had ten different categories. We displayed random images and realized that they are different fashion products as the name suggests. \n",
    "\n",
    "We created a perceptron with a single hidden layer with 512 nodes. Its accuracy was about 88% on the test set. This was not mentioned in the question but we tried it just to set the benchmark for the most basic NN model. </br>\n",
    "\n",
    "We also created a multi-layered perceptron as mentioned in the question. It was tending to overfit after a 10 epochs. Thus we \n",
    "retrained the model to run only for 10 epochs. We chose to go with the funneling technique reducing the number of nodes in each layer. This was one of the many techniques discussed in class. The accuracy was around 88% on the test set. The surprising this here was despite addition of three hidden layers, there was no improvement in accuracy. </br>\n",
    "\n",
    "We then created a CNN model. We added two sequences of convulusion-pooling-dropout based on the parameters to the best of our intuition. This model was two percentage points better than the multi-layer perceptron. </br>\n",
    "\n",
    "After Image preprocessing we tried the models again. We only implemented scaling in validation data set and no other transformations. We noticed that after this the performance of CNN improved but not of the MLP. This might be attributed to the fact that the CNN learns local pattersn irrespective to its placement in the image unlike the MLP. Thus its performance improvement as it was able to patternize better. Our next step would be trying different combinations of parameters and different pre-trained networks to make things better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
